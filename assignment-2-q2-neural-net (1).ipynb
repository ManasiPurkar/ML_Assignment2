{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7167269,"sourceType":"datasetVersion","datasetId":4140528}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-14T08:01:04.439192Z","iopub.execute_input":"2023-12-14T08:01:04.439719Z","iopub.status.idle":"2023-12-14T08:01:04.451523Z","shell.execute_reply.started":"2023-12-14T08:01:04.439681Z","shell.execute_reply":"2023-12-14T08:01:04.450088Z"},"trusted":true},"execution_count":381,"outputs":[{"name":"stdout","text":"/kaggle/input/regression-dataset/Assignment2_q2_dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Load data from CSV file\ndata = pd.read_csv('/kaggle/input/regression-dataset/Assignment2_q2_dataset.csv')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.455454Z","iopub.execute_input":"2023-12-14T08:01:04.455965Z","iopub.status.idle":"2023-12-14T08:01:04.519340Z","shell.execute_reply.started":"2023-12-14T08:01:04.455924Z","shell.execute_reply":"2023-12-14T08:01:04.518265Z"},"trusted":true},"execution_count":382,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.521025Z","iopub.execute_input":"2023-12-14T08:01:04.521849Z","iopub.status.idle":"2023-12-14T08:01:04.544704Z","shell.execute_reply.started":"2023-12-14T08:01:04.521809Z","shell.execute_reply":"2023-12-14T08:01:04.543289Z"},"trusted":true},"execution_count":383,"outputs":[{"execution_count":383,"output_type":"execute_result","data":{"text/plain":"           id   Date  number of bedrooms  number of bathrooms  living area  \\\n0  6762810145  42491                   5                 2.50         3650   \n1  6762810635  42491                   4                 2.50         2920   \n2  6762810998  42491                   5                 2.75         2910   \n3  6762812605  42491                   4                 2.50         3310   \n4  6762812919  42491                   3                 2.00         2710   \n\n   lot area  number of floors  waterfront present  number of views  \\\n0      9050               2.0                   0                4   \n1      4000               1.5                   0                0   \n2      9480               1.5                   0                0   \n3     42998               2.0                   0                0   \n4      4500               1.5                   0                0   \n\n   condition of the house  grade of the house  \\\n0                       5                  10   \n1                       5                   8   \n2                       3                   8   \n3                       3                   9   \n4                       4                   8   \n\n   Area of the house(excluding basement)  Area of the basement  Built Year  \\\n0                                   3370                   280        1921   \n1                                   1910                  1010        1909   \n2                                   2910                     0        1939   \n3                                   3310                     0        2001   \n4                                   1880                   830        1929   \n\n   Renovation Year  Postal Code  Lattitude  Longitude  living_area_renov  \\\n0                0       122003    52.8645   -114.557               2880   \n1                0       122004    52.8878   -114.470               2470   \n2                0       122004    52.8852   -114.468               2940   \n3                0       122005    52.9532   -114.321               3350   \n4                0       122006    52.9047   -114.485               2060   \n\n   lot_area_renov  Number of schools nearby  Distance from the airport  \\\n0            5400                         2                         58   \n1            4000                         2                         51   \n2            6600                         1                         53   \n3           42847                         3                         76   \n4            4500                         1                         51   \n\n     Price  \n0  2380000  \n1  1400000  \n2  1200000  \n3   838000  \n4   805000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Date</th>\n      <th>number of bedrooms</th>\n      <th>number of bathrooms</th>\n      <th>living area</th>\n      <th>lot area</th>\n      <th>number of floors</th>\n      <th>waterfront present</th>\n      <th>number of views</th>\n      <th>condition of the house</th>\n      <th>grade of the house</th>\n      <th>Area of the house(excluding basement)</th>\n      <th>Area of the basement</th>\n      <th>Built Year</th>\n      <th>Renovation Year</th>\n      <th>Postal Code</th>\n      <th>Lattitude</th>\n      <th>Longitude</th>\n      <th>living_area_renov</th>\n      <th>lot_area_renov</th>\n      <th>Number of schools nearby</th>\n      <th>Distance from the airport</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6762810145</td>\n      <td>42491</td>\n      <td>5</td>\n      <td>2.50</td>\n      <td>3650</td>\n      <td>9050</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>5</td>\n      <td>10</td>\n      <td>3370</td>\n      <td>280</td>\n      <td>1921</td>\n      <td>0</td>\n      <td>122003</td>\n      <td>52.8645</td>\n      <td>-114.557</td>\n      <td>2880</td>\n      <td>5400</td>\n      <td>2</td>\n      <td>58</td>\n      <td>2380000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6762810635</td>\n      <td>42491</td>\n      <td>4</td>\n      <td>2.50</td>\n      <td>2920</td>\n      <td>4000</td>\n      <td>1.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>8</td>\n      <td>1910</td>\n      <td>1010</td>\n      <td>1909</td>\n      <td>0</td>\n      <td>122004</td>\n      <td>52.8878</td>\n      <td>-114.470</td>\n      <td>2470</td>\n      <td>4000</td>\n      <td>2</td>\n      <td>51</td>\n      <td>1400000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6762810998</td>\n      <td>42491</td>\n      <td>5</td>\n      <td>2.75</td>\n      <td>2910</td>\n      <td>9480</td>\n      <td>1.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>8</td>\n      <td>2910</td>\n      <td>0</td>\n      <td>1939</td>\n      <td>0</td>\n      <td>122004</td>\n      <td>52.8852</td>\n      <td>-114.468</td>\n      <td>2940</td>\n      <td>6600</td>\n      <td>1</td>\n      <td>53</td>\n      <td>1200000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6762812605</td>\n      <td>42491</td>\n      <td>4</td>\n      <td>2.50</td>\n      <td>3310</td>\n      <td>42998</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>9</td>\n      <td>3310</td>\n      <td>0</td>\n      <td>2001</td>\n      <td>0</td>\n      <td>122005</td>\n      <td>52.9532</td>\n      <td>-114.321</td>\n      <td>3350</td>\n      <td>42847</td>\n      <td>3</td>\n      <td>76</td>\n      <td>838000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6762812919</td>\n      <td>42491</td>\n      <td>3</td>\n      <td>2.00</td>\n      <td>2710</td>\n      <td>4500</td>\n      <td>1.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>8</td>\n      <td>1880</td>\n      <td>830</td>\n      <td>1929</td>\n      <td>0</td>\n      <td>122006</td>\n      <td>52.9047</td>\n      <td>-114.485</td>\n      <td>2060</td>\n      <td>4500</td>\n      <td>1</td>\n      <td>51</td>\n      <td>805000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for column in data.columns:\n    non_numeric_mask = pd.to_numeric(data[column], errors='coerce').isna()\n    if non_numeric_mask.any():\n        print(f\"Non-numeric data found in column '{column}' at positions:\")\n        print(data[non_numeric_mask][column])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.547229Z","iopub.execute_input":"2023-12-14T08:01:04.547752Z","iopub.status.idle":"2023-12-14T08:01:04.564603Z","shell.execute_reply.started":"2023-12-14T08:01:04.547703Z","shell.execute_reply":"2023-12-14T08:01:04.562779Z"},"trusted":true},"execution_count":384,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"display.max_rows\", None)\npd.set_option(\"display.max_columns\", None)\ndata.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.568141Z","iopub.execute_input":"2023-12-14T08:01:04.569288Z","iopub.status.idle":"2023-12-14T08:01:04.584061Z","shell.execute_reply.started":"2023-12-14T08:01:04.569238Z","shell.execute_reply":"2023-12-14T08:01:04.580452Z"},"trusted":true},"execution_count":385,"outputs":[{"execution_count":385,"output_type":"execute_result","data":{"text/plain":"id                                       0\nDate                                     0\nnumber of bedrooms                       0\nnumber of bathrooms                      0\nliving area                              0\nlot area                                 0\nnumber of floors                         0\nwaterfront present                       0\nnumber of views                          0\ncondition of the house                   0\ngrade of the house                       0\nArea of the house(excluding basement)    0\nArea of the basement                     0\nBuilt Year                               0\nRenovation Year                          0\nPostal Code                              0\nLattitude                                0\nLongitude                                0\nliving_area_renov                        0\nlot_area_renov                           0\nNumber of schools nearby                 0\nDistance from the airport                0\nPrice                                    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.586962Z","iopub.execute_input":"2023-12-14T08:01:04.587423Z","iopub.status.idle":"2023-12-14T08:01:04.613914Z","shell.execute_reply.started":"2023-12-14T08:01:04.587386Z","shell.execute_reply":"2023-12-14T08:01:04.612173Z"},"trusted":true},"execution_count":386,"outputs":[{"execution_count":386,"output_type":"execute_result","data":{"text/plain":"           id   Date  number of bedrooms  number of bathrooms  living area  \\\n0  6762810145  42491                   5                 2.50         3650   \n1  6762810635  42491                   4                 2.50         2920   \n2  6762810998  42491                   5                 2.75         2910   \n3  6762812605  42491                   4                 2.50         3310   \n4  6762812919  42491                   3                 2.00         2710   \n\n   lot area  number of floors  waterfront present  number of views  \\\n0      9050               2.0                   0                4   \n1      4000               1.5                   0                0   \n2      9480               1.5                   0                0   \n3     42998               2.0                   0                0   \n4      4500               1.5                   0                0   \n\n   condition of the house  grade of the house  \\\n0                       5                  10   \n1                       5                   8   \n2                       3                   8   \n3                       3                   9   \n4                       4                   8   \n\n   Area of the house(excluding basement)  Area of the basement  Built Year  \\\n0                                   3370                   280        1921   \n1                                   1910                  1010        1909   \n2                                   2910                     0        1939   \n3                                   3310                     0        2001   \n4                                   1880                   830        1929   \n\n   Renovation Year  Postal Code  Lattitude  Longitude  living_area_renov  \\\n0                0       122003    52.8645   -114.557               2880   \n1                0       122004    52.8878   -114.470               2470   \n2                0       122004    52.8852   -114.468               2940   \n3                0       122005    52.9532   -114.321               3350   \n4                0       122006    52.9047   -114.485               2060   \n\n   lot_area_renov  Number of schools nearby  Distance from the airport  \\\n0            5400                         2                         58   \n1            4000                         2                         51   \n2            6600                         1                         53   \n3           42847                         3                         76   \n4            4500                         1                         51   \n\n     Price  \n0  2380000  \n1  1400000  \n2  1200000  \n3   838000  \n4   805000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Date</th>\n      <th>number of bedrooms</th>\n      <th>number of bathrooms</th>\n      <th>living area</th>\n      <th>lot area</th>\n      <th>number of floors</th>\n      <th>waterfront present</th>\n      <th>number of views</th>\n      <th>condition of the house</th>\n      <th>grade of the house</th>\n      <th>Area of the house(excluding basement)</th>\n      <th>Area of the basement</th>\n      <th>Built Year</th>\n      <th>Renovation Year</th>\n      <th>Postal Code</th>\n      <th>Lattitude</th>\n      <th>Longitude</th>\n      <th>living_area_renov</th>\n      <th>lot_area_renov</th>\n      <th>Number of schools nearby</th>\n      <th>Distance from the airport</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6762810145</td>\n      <td>42491</td>\n      <td>5</td>\n      <td>2.50</td>\n      <td>3650</td>\n      <td>9050</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>5</td>\n      <td>10</td>\n      <td>3370</td>\n      <td>280</td>\n      <td>1921</td>\n      <td>0</td>\n      <td>122003</td>\n      <td>52.8645</td>\n      <td>-114.557</td>\n      <td>2880</td>\n      <td>5400</td>\n      <td>2</td>\n      <td>58</td>\n      <td>2380000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6762810635</td>\n      <td>42491</td>\n      <td>4</td>\n      <td>2.50</td>\n      <td>2920</td>\n      <td>4000</td>\n      <td>1.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>8</td>\n      <td>1910</td>\n      <td>1010</td>\n      <td>1909</td>\n      <td>0</td>\n      <td>122004</td>\n      <td>52.8878</td>\n      <td>-114.470</td>\n      <td>2470</td>\n      <td>4000</td>\n      <td>2</td>\n      <td>51</td>\n      <td>1400000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6762810998</td>\n      <td>42491</td>\n      <td>5</td>\n      <td>2.75</td>\n      <td>2910</td>\n      <td>9480</td>\n      <td>1.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>8</td>\n      <td>2910</td>\n      <td>0</td>\n      <td>1939</td>\n      <td>0</td>\n      <td>122004</td>\n      <td>52.8852</td>\n      <td>-114.468</td>\n      <td>2940</td>\n      <td>6600</td>\n      <td>1</td>\n      <td>53</td>\n      <td>1200000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6762812605</td>\n      <td>42491</td>\n      <td>4</td>\n      <td>2.50</td>\n      <td>3310</td>\n      <td>42998</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>9</td>\n      <td>3310</td>\n      <td>0</td>\n      <td>2001</td>\n      <td>0</td>\n      <td>122005</td>\n      <td>52.9532</td>\n      <td>-114.321</td>\n      <td>3350</td>\n      <td>42847</td>\n      <td>3</td>\n      <td>76</td>\n      <td>838000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6762812919</td>\n      <td>42491</td>\n      <td>3</td>\n      <td>2.00</td>\n      <td>2710</td>\n      <td>4500</td>\n      <td>1.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>8</td>\n      <td>1880</td>\n      <td>830</td>\n      <td>1929</td>\n      <td>0</td>\n      <td>122006</td>\n      <td>52.9047</td>\n      <td>-114.485</td>\n      <td>2060</td>\n      <td>4500</td>\n      <td>1</td>\n      <td>51</td>\n      <td>805000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'data' is your DataFrame\ndata_types = data.dtypes\n\n# Display the data types of all columns\nprint(data_types)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.616646Z","iopub.execute_input":"2023-12-14T08:01:04.617576Z","iopub.status.idle":"2023-12-14T08:01:04.629252Z","shell.execute_reply.started":"2023-12-14T08:01:04.617526Z","shell.execute_reply":"2023-12-14T08:01:04.627611Z"},"trusted":true},"execution_count":387,"outputs":[{"name":"stdout","text":"id                                         int64\nDate                                       int64\nnumber of bedrooms                         int64\nnumber of bathrooms                      float64\nliving area                                int64\nlot area                                   int64\nnumber of floors                         float64\nwaterfront present                         int64\nnumber of views                            int64\ncondition of the house                     int64\ngrade of the house                         int64\nArea of the house(excluding basement)      int64\nArea of the basement                       int64\nBuilt Year                                 int64\nRenovation Year                            int64\nPostal Code                                int64\nLattitude                                float64\nLongitude                                float64\nliving_area_renov                          int64\nlot_area_renov                             int64\nNumber of schools nearby                   int64\nDistance from the airport                  int64\nPrice                                      int64\ndtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Extract input features (X) and target variable (Y)\n# X = data.drop('Price', axis=1).values  # Assuming 'Price' is the target variable\n# Y = data['Price'].values.reshape(-1, 1)\n\n# # Normalize the input features (optional but recommended)\n# X = (X - np.mean(X)) / np.std(X)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.631503Z","iopub.execute_input":"2023-12-14T08:01:04.632857Z","iopub.status.idle":"2023-12-14T08:01:04.643631Z","shell.execute_reply.started":"2023-12-14T08:01:04.632791Z","shell.execute_reply":"2023-12-14T08:01:04.641859Z"},"trusted":true},"execution_count":388,"outputs":[]},{"cell_type":"code","source":"# print(\"Shape of X:\", X.shape)\n# print(\"Shape of Y:\", Y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.656780Z","iopub.execute_input":"2023-12-14T08:01:04.657627Z","iopub.status.idle":"2023-12-14T08:01:04.662786Z","shell.execute_reply.started":"2023-12-14T08:01:04.657496Z","shell.execute_reply":"2023-12-14T08:01:04.661549Z"},"trusted":true},"execution_count":389,"outputs":[]},{"cell_type":"code","source":"data=data.drop(columns=['Date','id'])","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.666062Z","iopub.execute_input":"2023-12-14T08:01:04.666547Z","iopub.status.idle":"2023-12-14T08:01:04.677094Z","shell.execute_reply.started":"2023-12-14T08:01:04.666509Z","shell.execute_reply":"2023-12-14T08:01:04.675862Z"},"trusted":true},"execution_count":390,"outputs":[]},{"cell_type":"code","source":"x=data.drop(columns=['Price'])\ny=data['Price']\nx = x.apply(pd.to_numeric, errors='coerce')\n\n# Handle missing or non-numeric values\nx = x.fillna(0)  # You can replace NaN with 0 or choose another strategy\nx = np.asarray(x, dtype='float64')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.679008Z","iopub.execute_input":"2023-12-14T08:01:04.679462Z","iopub.status.idle":"2023-12-14T08:01:04.702388Z","shell.execute_reply.started":"2023-12-14T08:01:04.679399Z","shell.execute_reply":"2023-12-14T08:01:04.700896Z"},"trusted":true},"execution_count":391,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test,Y_train, Y_test = train_test_split(x,y,\n                                   random_state=104,\n                                   test_size=0.20,\n                                   shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.708184Z","iopub.execute_input":"2023-12-14T08:01:04.709408Z","iopub.status.idle":"2023-12-14T08:01:04.721552Z","shell.execute_reply.started":"2023-12-14T08:01:04.709353Z","shell.execute_reply":"2023-12-14T08:01:04.719921Z"},"trusted":true},"execution_count":392,"outputs":[]},{"cell_type":"code","source":"# X_train = (X_train - np.mean(X_train)) / np.std(X_train)\n# X_test = (X_test - np.mean(X_test)) / np.std(X_test)\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.723487Z","iopub.execute_input":"2023-12-14T08:01:04.724381Z","iopub.status.idle":"2023-12-14T08:01:04.739564Z","shell.execute_reply.started":"2023-12-14T08:01:04.724339Z","shell.execute_reply":"2023-12-14T08:01:04.737404Z"},"trusted":true},"execution_count":393,"outputs":[]},{"cell_type":"code","source":"# X_train = X_train.astype(float)\n# Y_train = Y_train.astype(float)\n# X_test = X_test.astype(float)\n# Y_test = Y_test.astype(float)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.740901Z","iopub.execute_input":"2023-12-14T08:01:04.741268Z","iopub.status.idle":"2023-12-14T08:01:04.747935Z","shell.execute_reply.started":"2023-12-14T08:01:04.741236Z","shell.execute_reply":"2023-12-14T08:01:04.746421Z"},"trusted":true},"execution_count":394,"outputs":[]},{"cell_type":"code","source":"print(X_train.T)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.749516Z","iopub.execute_input":"2023-12-14T08:01:04.749900Z","iopub.status.idle":"2023-12-14T08:01:04.762550Z","shell.execute_reply.started":"2023-12-14T08:01:04.749869Z","shell.execute_reply":"2023-12-14T08:01:04.761587Z"},"trusted":true},"execution_count":395,"outputs":[{"name":"stdout","text":"[[-1.46201736e+00 -1.46201736e+00  6.60989038e-01 ...  1.72249224e+00\n  -1.46201736e+00 -4.00514160e-01]\n [-1.46803590e+00 -1.46803590e+00  8.01603711e-01 ... -1.71098980e-01\n  -1.46803590e+00 -1.46803590e+00]\n [-9.87939061e-01 -1.11667886e+00  3.20915532e-01 ... -4.30066611e-01\n  -1.22396202e+00 -6.98274520e-01]\n ...\n [-2.11536933e-01 -2.11536933e-01 -3.37688407e-01 ... -2.12439089e-01\n  -3.28817207e-01 -9.12494730e-02]\n [ 1.21098106e+00 -1.23608779e+00  1.21098106e+00 ...  1.21098106e+00\n  -1.25533628e-02 -1.23608779e+00]\n [-3.83242114e-04 -1.12098318e+00 -5.60683212e-01 ...  2.23736746e-01\n   1.56845667e+00  5.59916728e-01]]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"X_train shape:\", X_train.shape)\nprint(\"X_test shape:\", X_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.764614Z","iopub.execute_input":"2023-12-14T08:01:04.765033Z","iopub.status.idle":"2023-12-14T08:01:04.782446Z","shell.execute_reply.started":"2023-12-14T08:01:04.764997Z","shell.execute_reply":"2023-12-14T08:01:04.780514Z"},"trusted":true},"execution_count":396,"outputs":[{"name":"stdout","text":"X_train shape: (11696, 20)\nX_test shape: (2924, 20)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(y.shape)\ny = y.to_numpy().reshape(1, -1)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.784653Z","iopub.execute_input":"2023-12-14T08:01:04.785297Z","iopub.status.idle":"2023-12-14T08:01:04.794280Z","shell.execute_reply.started":"2023-12-14T08:01:04.785243Z","shell.execute_reply":"2023-12-14T08:01:04.792753Z"},"trusted":true},"execution_count":397,"outputs":[{"name":"stdout","text":"(14620,)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.798833Z","iopub.execute_input":"2023-12-14T08:01:04.799751Z","iopub.status.idle":"2023-12-14T08:01:04.807351Z","shell.execute_reply.started":"2023-12-14T08:01:04.799701Z","shell.execute_reply":"2023-12-14T08:01:04.806223Z"},"trusted":true},"execution_count":398,"outputs":[{"name":"stdout","text":"(1, 14620)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n# initialize weights and biases\ndef initialize_parameters(input_size, hidden_size, output_size):\n    np.random.seed(0)\n    W1 = np.random.randn(hidden_size, input_size) * 0.01\n    b1 = np.zeros((hidden_size, 1))\n    W2 = np.random.randn(output_size, hidden_size) * 0.01\n    b2 = np.zeros((output_size, 1))\n    parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n    return parameters\n\n# parameters = initialize_parameters(2, 3, 1)\n\n\n# sigmoid activation function\ndef sigmoid(x):\n    clipped_x = np.clip(x, -500, 500)\n    return 1 / (1 + np.exp(-clipped_x))\n\n# forward propagation\n# forward propagation\ndef forward_propagation(X, parameters):\n#     print(\"Parameters:\", parameters)\n    # retrieve the parameters\n    W1, b1, W2, b2 = parameters[\"W1\"], parameters[\"b1\"], parameters[\"W2\"], parameters[\"b2\"]\n    \n    # Print shapes for debugging\n    \n#     print(\"X shape:\", X.shape)\n#     print(\"W1 shape:\", W1.shape)\n#     print(\"b1 shape:\", b1.shape)\n    \n    # compute the activation of the hidden layer\n    Z1 = np.dot(W1, X.T) + b1\n    A1 = sigmoid(Z1)\n    \n    # Print shapes for debugging\n#     print(\"Z1 shape:\", Z1.shape)\n#     print(\"A1 shape:\", A1.shape)\n    \n    # compute the activation of the output layer\n    Z2 = np.dot(W2, A1) + b2\n    A2 = sigmoid(Z2)\n    \n    # Print shapes for debugging\n#     print(\"Z2 shape:\", Z2.shape)\n#     print(\"A2 shape:\", A2.shape)\n    \n    cache = {\"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2}\n    \n    return A2, cache\n\n\n# A2, cache = forward_propagation(X_train, parameters)\n\n# mean square error\n# def mean_squared_error_loss(A2, y):\n#     m = y.shape[1]  # Assuming each column represents a sample\n    \n#     # Check and reshape if necessary\n#     if A2.shape != y.shape:\n#         A2 = A2.reshape(y.shape)  # Reshape A2 to match the shape of y\n\n#     # Calculate mean squared error\n#     loss = (1/m) * np.sum((A2 - y)**2)\n#     return loss\n# mean square error\n# mean square error\n# mean square error\ndef mean_squared_error_loss(A2, y):\n#     print(y.shape[1])\n#     m = y.shape[1]\n    \n    # Convert pandas Series to NumPy array and reshape\n    #y = np.array(y).reshape(1, -1)\n    # Assuming y is a DataFrame or Series\n    y = y.to_numpy().reshape(1, -1)  # Convert to NumPy array\n\n    # Now you can check the shape\n#     print(y.shape[1])\n    m = y.shape[1]\n    # Ensure y has the same shape as A2\n    if y.shape != A2.shape:\n        raise ValueError(\"Shapes of A2 and y do not match\")\n    \n    loss = (1/m) * np.sum((A2 - y)**2)\n    return loss\n\n\n\n\n# backward propagation\ndef backward_propagation(parameters, cache, X, y):\n#     y = y.to_numpy().reshape(1, -1)  # Convert to NumPy array\n\n#     print(y.shape[1])\n    y = y.to_numpy().reshape(1, -1).astype(float)\n    m = y.shape[1]\n    \n    \n    # retrieve the intermediate values\n    Z1 = cache[\"Z1\"]\n    A1 = cache[\"A1\"]\n    Z2 = cache[\"Z2\"]\n    A2 = cache[\"A2\"]\n    \n    # compute the derivative of the loss with respect to A2\n#     dA2 = - (y/A2) + ((1-y)/(1-A2))\n    dA2 = - np.divide(y, A2, out=np.zeros_like(y), where=(A2 != 0)) + np.divide((1 - y), (1 - A2), out=np.zeros_like(y), where=((1 - A2) != 0))\n\n    \n    # compute the derivative of the activation function of the output layer\n    dZ2 = dA2 * (A2 * (1-A2))\n    \n    # compute the derivative of the weights and biases of the output layer\n    dW2 = (1/m) * np.dot(dZ2, A1.T)\n    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n    \n    # compute the derivative of the activation function of the hidden layer\n    dA1 = np.dot(parameters[\"W2\"].T, dZ2)\n    dZ1 = dA1 * (A1 * (1-A1))\n    \n    # compute the derivative of the weights and biases of the hidden layer\n    dW1 = (1/m) * np.dot(dZ1, X)\n    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n    gradients = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n\n    return gradients\n\n# update parameters\ndef update_parameters(parameters, gradients, learning_rate):\n    # retrieve the gradients\n    dW1 = gradients[\"dW1\"]\n    db1 = gradients[\"db1\"]\n    dW2 = gradients[\"dW2\"]\n    db2 = gradients[\"db2\"]\n    \n    # retrieve the weights and biases\n    W1 = parameters[\"W1\"]\n    b1 = parameters[\"b1\"]\n    W2 = parameters[\"W2\"]\n    b2 = parameters[\"b2\"]\n    \n    # update the weights and biases\n    W1 = W1 - learning_rate*dW1\n    b1 = b1 - learning_rate*db1\n    W2 = W2 - learning_rate*dW2\n    b2 = b2 - learning_rate*db2\n    \n    parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n    \n    return parameters\n\n# train the neural network\ndef train(X, y, hidden_layer_size, num_iterations, learning_rate):\n    # initialize the weights and biases\n#     print(X.shape[1])\n#     print(hidden_layer_size)\n    parameters = initialize_parameters(X.shape[1], hidden_layer_size, 1)\n    \n    for i in range(num_iterations):\n        # forward propagation\n        A2, cache = forward_propagation(X, parameters)\n        \n        # compute the loss\n        loss = mean_squared_error_loss(A2, y)\n        \n        # backward propagation\n        gradients = backward_propagation(parameters, cache, X, y)\n        \n        # update the parameters\n        parameters = update_parameters(parameters, gradients, learning_rate)\n        \n        if i % 1000 == 0:\n            print(f\"iteration {i}: loss = {loss}\")\n    \n    return parameters\n\nparameters = train(X_train, Y_train, hidden_layer_size=4, num_iterations=10000, learning_rate=0.1)\n\n# predict the labels for new data\ndef predict(X, parameters):\n    A2, _ = forward_propagation(X, parameters)\n    predictions = (A2 > 0.5).astype(int)\n    return predictions\npredictions = predict(X_test, parameters)\n\n\n# Compute the MSE for X_test\nmse_test = mean_squared_error_loss(predictions,Y_test)\n\nprint(f'Mean Squared Error for X_test: {mse_test}')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:04.809235Z","iopub.execute_input":"2023-12-14T08:01:04.809930Z","iopub.status.idle":"2023-12-14T08:01:55.116649Z","shell.execute_reply.started":"2023-12-14T08:01:04.809884Z","shell.execute_reply":"2023-12-14T08:01:55.114909Z"},"trusted":true},"execution_count":399,"outputs":[{"name":"stdout","text":"iteration 0: loss = 426637469569.66064\niteration 1000: loss = 426636928309.6398\niteration 2000: loss = 426636928309.6398\niteration 3000: loss = 426636928309.6398\niteration 4000: loss = 426636928309.6398\niteration 5000: loss = 426636928309.6398\niteration 6000: loss = 426636928309.6398\niteration 7000: loss = 426636928309.6398\niteration 8000: loss = 426636928309.6398\niteration 9000: loss = 426636928309.6398\nMean Squared Error for X_test: 421040634909.724\n","output_type":"stream"}]},{"cell_type":"code","source":"print(np.isnan(X_train).sum())\nprint(np.isnan(Y_train).sum())\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:55.126592Z","iopub.execute_input":"2023-12-14T08:01:55.127889Z","iopub.status.idle":"2023-12-14T08:01:55.146967Z","shell.execute_reply.started":"2023-12-14T08:01:55.127810Z","shell.execute_reply":"2023-12-14T08:01:55.145755Z"},"trusted":true},"execution_count":400,"outputs":[{"name":"stdout","text":"0\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"# import numpy as np\n\n# def initialize_parameters(input_size, hidden_size, output_size):\n#     np.random.seed(42)\n    \n#     # Weights and biases initialization\n#     W1 = np.random.randn(hidden_size, input_size) * 0.01\n#     b1 = np.zeros((hidden_size, 1))\n#     W2 = np.random.randn(output_size, hidden_size) * 0.01\n#     b2 = np.zeros((output_size, 1))\n\n#     parameters = {\n#         \"W1\": W1,\n#         \"b1\": b1,\n#         \"W2\": W2,\n#         \"b2\": b2\n#     }\n\n#     return parameters\n\n# def relu(Z):\n#     return np.maximum(0, Z)\n\n# def linear_forward(A, W, b):\n#     Z = np.dot(W, A) + b\n#     cache = (A, W, b)\n#     return Z, cache\n\n# def forward_propagation(X, parameters):\n#     # Retrieve parameters\n#     W1, b1, W2, b2 = parameters\n    \n#     # Forward pass\n#     Z1, cache1 = linear_forward(X, W1, b1)\n#     A1 = relu(Z1)\n#     Z2, cache2 = linear_forward(A1, W2, b2)\n#     A2 = Z2  # Linear activation for regression\n\n#     cache = {\n#         \"cache1\": cache1,\n#         \"cache2\": cache2\n#     }\n\n#     return A2, cache\n\n# def compute_cost(A2, Y):\n#     m = Y.shape[1]\n#     cost = (1 / (2 * m)) * np.sum((A2 - Y)**2)\n#     return cost\n\n# def linear_backward(dZ, cache):\n#     A_prev, W, b = cache\n#     m = A_prev.shape[1]\n\n#     dW = (1 / m) * np.dot(dZ, A_prev.T)\n#     db = (1 / m) * np.sum(dZ, axis=1, keepdims=True)\n#     dA_prev = np.dot(W.T, dZ)\n\n#     return dA_prev, dW, db\n\n# def relu_backward(dA, Z):\n#     dZ = np.array(dA, copy=True)\n#     dZ[Z <= 0] = 0\n#     return dZ\n\n# def backward_propagation(parameters, cache, X, Y):\n#     m = X.shape[1]\n#     W1, b1, W2, b2 = parameters\n#     A1, W1, b1 = cache[\"cache1\"]\n#     A2, W2, b2 = cache[\"cache2\"]\n\n#     # Compute gradients\n#     dZ2 = A2 - Y\n#     dA1, dW2, db2 = linear_backward(dZ2, (A1, W2, b2))\n#     dZ1 = relu_backward(dA1, A1)\n#     dA0, dW1, db1 = linear_backward(dZ1, (X, W1, b1))\n\n#     # Update parameters\n#     parameters[\"W1\"] -= dW1\n#     parameters[\"b1\"] -= db1\n#     parameters[\"W2\"] -= dW2\n#     parameters[\"b2\"] -= db2\n\n#     return parameters\n\n# def train_neural_network(X, Y, hidden_size, learning_rate, num_epochs):\n#     input_size = X.shape[0]\n#     output_size = Y.shape[0]\n\n#     # Initialize parameters\n#     parameters = initialize_parameters(input_size, hidden_size, output_size)\n\n#     for epoch in range(num_epochs):\n#         # Forward propagation\n#         A2, cache = forward_propagation(X, parameters)\n\n#         # Compute cost\n#         cost = compute_cost(A2, Y)\n\n#         # Backward propagation\n#         parameters = backward_propagation(parameters, cache, X, Y)\n\n#         # Print cost every 100 epochs\n#         if epoch % 100 == 0:\n#             print(f\"Epoch {epoch}/{num_epochs}, Cost: {cost}\")\n\n#     return parameters\n\n\n\n# # Hyperparameters\n# hidden_size = 4\n# learning_rate = 0.01\n# num_epochs = 1000\n\n# # Train the neural network\n# trained_parameters = train_neural_network(X_train, Y_train, hidden_size, learning_rate, num_epochs)\n\n# # Make predictions on new data\n# predicted_price, _ = forward_propagation(X_test, trained_parameters)\n\n# print(\"Predicted Price:\", predicted_price)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:01:55.149343Z","iopub.execute_input":"2023-12-14T08:01:55.150335Z","iopub.status.idle":"2023-12-14T08:01:55.165009Z","shell.execute_reply.started":"2023-12-14T08:01:55.150271Z","shell.execute_reply":"2023-12-14T08:01:55.162880Z"},"trusted":true},"execution_count":401,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}